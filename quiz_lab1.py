# -*- coding: utf-8 -*-
"""quiz on the spot 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bk-CrzsDrW7jd5_VdLwGtCITJ6yVJlyN
"""

import pandas as pd
import numpy as np

# load the data
data = pd.read_csv('/content/DSAI-LVA-DATASET for Quiz.csv')

# size of the test set
test_size_ratio = 0.3
num_data_points = len(data)
num_test_samples = int(num_data_points * test_size_ratio)

# shuffle the data before splitting (if desired)
np.random.seed(42)
shuffled_indices = np.random.permutation(num_data_points)

# split the indices into training and test sets
test_indices = shuffled_indices[:num_test_samples]
train_indices = shuffled_indices[num_test_samples:]

# create the training and test sets
train_data = data.iloc[train_indices]
test_data = data.iloc[test_indices]

# save the split data into separate files
train_data.to_csv('student_train_manual.csv', index=False)
test_data.to_csv('student_test_manual.csv', index=False)

print(f"Training data manually saved to 'student_train_manual.csv'")
print(f"Testing data manually saved to 'student_test_manual.csv'")

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Load training and testing data
train_data = pd.read_csv('student_train_manual.csv')
test_data = pd.read_csv('student_test_manual.csv')

# Preparing the features and target variable
features = train_data.columns[:-1]  # Exclude the target variable
X_train = train_data[features]
y_train = train_data['Pass']
X_test = test_data[features]
y_test = test_data['Pass']

# Encode categorical data and scale numerical data
categorical_features = ['ParentEducation']
numerical_features = ['StudyTime', 'PreviousTestScore']

numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder()

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Encode the target variable using LabelEncoder
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Preprocess the features
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_test_preprocessed = preprocessor.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Define the models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
}

# Train the models and evaluate accuracy
accuracy_scores = {}

for name, model in models.items():
    model.fit(X_train_preprocessed, y_train_encoded)
    y_pred = model.predict(X_test_preprocessed)
    accuracy = accuracy_score(y_test_encoded, y_pred)
    accuracy_scores[name] = accuracy
    print(f"{name} Accuracy: {accuracy:.4f}")

plt.figure(figsize=(10, 6))
plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color=['blue', 'green', 'red'])
plt.xlabel('Model')
plt.ylabel('Accuracy Score')
plt.title('Comparison of Model Accuracy in Multiclass Classification')
plt.show()

with open('model_comparison_results_multiclass.txt', 'w') as file:
    for model, accuracy in accuracy_scores.items():
        file.write(f"{model} Accuracy: {accuracy:.4f}\n")

print("Model comparison and outcome written to 'model_comparison_results_multiclass.txt'")