# -*- coding: utf-8 -*-
"""LVADSUSR71_ARYAN_MITTAL_LAB-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n1tF2Mwb0Yug429rZkv0btxpK0dQOIIk
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/loan_approval.csv")

df.head()

df.info()

df.isnull().sum()   #for checking the null values

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features")
plt.xticks(rotation=45)
plt.show()  #boxplot for detetcting the outliers

#as we can see , there is no outlier in the data

df.drop_duplicates()   #droping the duplicates

df.describe()

sns.pairplot(df)

df.corr()

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

df.columns = df.columns.str.strip()

for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].str.strip()

# Encoding categorical variables and scaling numerical variables
categorical_features = ['education', 'self_employed']
numerical_features = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',
                      'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Prepare target variable and features
X = df.drop(['loan_id', 'loan_status'], axis=1)
y = df['loan_status']

X.head()

y.head()

# Splitting the dataset into training and testing set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
model = Pipeline(steps=[('preprocessor', preprocessor),
                        ('classifier', RandomForestClassifier(random_state=42))])

# Fit the model
model.fit(X_train, y_train)

# Predicting the Test set results
y_pred = model.predict(X_test)
y_pred

# Model Evaluation
from sklearn.metrics import classification_report, accuracy_score
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(accuracy)

print(classification_rep)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generating the confusion matrix for the model predictions
cm = confusion_matrix(y_test, y_pred)

# Plotting the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=model.classes_)

disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix for Loan Approval Prediction')
plt.show()

