# -*- coding: utf-8 -*-
"""LVADSUSR72_ARYAN_MITTAL_LAB-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SUoV7kVlHAN4Hr_Q6rFeZxxVQ9iVVEcP
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("/content/auto-mpg.csv")

df.head()

df.describe()

df.info()

df.isnull().sum()  #checking null values

df.columns = df.columns.str.strip()           #removing the whitespaces from the column names

for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].str.strip()

#removing the null values

# Convert 'horsepower' to numeric, and coerce errors to NaN to find and deal with them.
df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')

# Re-check for missing values after conversion
df.isnull().sum()

# Drop rows with missing values
df = df.dropna()

df.isnull().sum()

#cheking the outliers
plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features")
plt.xticks(rotation=45)
plt.show()

# Outliers detection and handling
# For this simple model, let's use a straightforward approach by removing outliers beyond 3 standard deviations from the mean.
from scipy import stats
import numpy as np

df = df[(np.abs(stats.zscore(df.select_dtypes(include=[np.number]))) < 3).all(axis=1)]

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features (outliers removed)")
plt.xticks(rotation=45)
plt.show()

df.shape

df.corr()

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# as we can see that , 5 features are very neagtively correlated
sns.pairplot(df)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Features and Target Variable
X = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']]
y = df['mpg']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Model Training
model = LinearRegression()
model.fit(X_train, y_train)

# Model Testing
y_pred = model.predict(X_test)
y_pred

# Model Evaluation Metrics
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

mse, rmse, r2

plt.figure(figsize=(10, 6))
sns.regplot(x=df['weight'], y=df['mpg'], scatter_kws={'alpha':0.5}, line_kws={'color':'red'})
plt.title('Regression Plot of MPG vs. Weight')
plt.xlabel('Weight')
plt.ylabel('MPG')
plt.show()

plt.figure(figsize=(10, 6))
sns.regplot(x=df['weight'], y=df['cylinders'], scatter_kws={'alpha':0.5}, line_kws={'color':'red'})
plt.title('Regression Plot of MPG vs. cylinders')
plt.xlabel('Weight')
plt.ylabel('MPG')
plt.show()

